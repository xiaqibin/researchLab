---
layout: post
title:  样本空间，事件与概率
category: [数学,随机过程] 
hide: true
description: 随机过程的基础还是概率论，本篇博客简单介绍概率论中的一些基本概念，主要是引入样本空间，事件和概率这三个基本概念
---

## 样本空间与事件

说到概率，我们首先要来解释一下什么样的事件是概率事件，而什么样的概率是我们研究的，我们说，如果一个事情在发生之前我们不能清楚其最后的结果是什么，那么可以广义的称这类事件是随机事件。如果我们能够多知道一点信息，即我们知道这个事件所有发生的结果有哪些，那么我们可以基于这些信息对事件的发生进行研究。

因此我们定义，一个概率模型的样本空间是所有可能发生的事件的结果（实际上这个定义不是很严格），我们记为$$S$$。举一个例子，丢一块硬币，出现的结果正面朝上记为H，反面朝上记为T，那么样本空间

$$
S = \{H,T\}
$$

有了样本空间，我们需要定义事件，这里是一个很重要的点，事件是样本空间的**子集**，因此，事件是一系列样本的集合。我们记事件为$$E$$，表示Event，

$$E\subset S$$

我们说事件发生了，代表事件中的样本出现了。引入集合的概念进入概率模型中，一方面是将一些概念数理化，使得在以后的阐述中不会出现歧义，另一方面也是简化了很多复杂事件的表示，因为集合的某些运算可以对应到事件的复合中，例如并运算与交运算代表了两种事件的逻辑复合，在这里不再多说了。

借助集合符号的运算，我们可以得到一些其他的概念，比如两个事件$$E$$与$$F$$相互排斥，定义为：

$$E\cap F = \emptyset$$

$$\emptyset$$代表一个事件，这个事件里面没有出现任何样本，这是一种扩展的样本空间的定义。

当然，事件的运算可以参照集合运算扩展到多个事件甚至是无穷个事件，代表的含义根据运算的逻辑来确定。另一方面，对于某个事件$$E$$，在样本空间中的补集$$E^\complement $$，称其为对立事件。

## 概率

我们需要理清的一个概念是，概率是定义在事件之上的，从测度论的角度来说，概率是衡量事件集合的测度，通常表示为$$P(E)$$，但是概率不是任意的一个测度，需要满足以下3个条件：

1. $$0\leq P(E) \leq 1$$
2. $$P(S)=1$$
3. 对于任意的事件$$E_1,E_2,\cdot$$，如果两两之间相互排斥，即$$\forall m\neq n, E_m\cap E_n=\emptyset$$，那么
   
$$ 
P(\bigcup_{i=1}^\infty{E_i}) = \sum_{i=1}^\infty{P(E_i)}
$$

上面三个条件需要关注的是第三个条件，它定义了对于可数个事件的概率计算方法

基于这个概率定义我们可以得到一些常见的概率计算公式，比如

$$
\begin{aligned}
    &P(\emptyset) = P(S\cup \emptyset) - P(S) = 0\\
    &P(E\cup F) = P(E) + P(F) - P(E\cap F)\\
    &P(E_1\cup \cdots \cup E_n) = \sum_{i=1}^n{P(E_i)} - \sum_{i<j}{P(E_i\cap E_j)} + \sum_{i<j<k}^n{P(E_i\cap E_j\cap E_k)}\\
    &+\cdots+(-1)^{n+1)}P(E_i\cap \cdots \cap E_n)
\end{aligned}
$$

## 条件概率

如果两个事件$$E$$或者$$F$$，我们想得到当$$F$$发生后，事件$$E$$发生的概率，因此自然引入条件概率的概念$$P(E\vert F)$$，并且有公式：

$$
P(E\vert F) = \frac{P(EF)}{P(F)}
$$

关于条件概率，我想谈论的是两点[^1]：
1. 条件概率的引入，使得概率本身有了乘法运算，我们从概率的定义上是无法自然引入两个概率相乘这一运算的。
2. 条件概率的计算公式的理解，实际上从本质上来说，是因为样本空间变化了导致的，$$E$$和$$F$$在没有条件概率下，样本空间是$$S$$，但是，当我们要求$$E$$关于$$F$$的条件概率时，我们的样本空间就不是在$$S$$中了，而是在事件$$F$$的那些样本中。从这一角度来看，任意概率都是定义在某一样本空间中的概率，因此可以将一般概率也看成扩展的条件概率，扩展条件就是在样本空间$$S$$的条件下，不过我们定义了$$P(S) = 1$$

[^1]: 关于概率的思考，由于概率是一种测度，因此似乎可以任意定测度的值域，从这点来看，可能条件概率更符合描述概率本质？

## 独立事件

如果两个事件，它们的概率满足

$$
\begin{aligned}
    &P(EF) = P(E)P(F)\\
    &P(E\vert F) = P(E)
\end{aligned}
$$

两个公式是等价的，那么称两个事件相互独立。

这里唯一需要注意的是独立事件与互斥事件的定义是不相同的，需要严格区分开。我们把互斥事件的定义发在下面：

$$
E\cap F = \emptyset
$$

而且通常来说，互斥事件并不是独立事件[^2]。

[^2]: 关于各个概念的分辨，其实很好掌握，只要牢牢抓住它们的定义，根据定义来区分，很多数学概念的区别和联系就自然而然呈现出来了

## 贝叶斯公式

设$$F_i$$是一系列互斥事件[^3]，且$$\bigcup_{i=1}^{n}{F_i} = S$$，那么对另一事件$$E$$有：

$$
\begin{aligned}
    P(E) &= \sum_{i=1}^n{P(EF_i)}\\
    &= \sum_{i=1}^n{P(E\vert F_i)P(F_i)}
\end{aligned}
$$

这个公式也被称为**全概率公式**

基于全概率公式，我们可以得到**贝叶斯公式**：

$$
\begin{aligned}
    P(F_i\vert E) &= \frac{P(EF_i)}{P_E}\\
    &=\frac{P(E \vert F_i)P(F_i)}{\sum_{i=1}^n{P(E\vert F_i)P(F_i)}}
\end{aligned}
$$

[^3]: 目前还不是很清楚对于可数个互斥事件贝叶斯公式是否仍然成立，这里暂时先留一个问题在这里

